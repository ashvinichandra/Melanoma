{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9598aa2",
   "metadata": {},
   "source": [
    "# Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis.\n",
    "\n",
    "Importing Skin Cancer Data\n",
    "To do: Take necessary actions to read the data\n",
    "Importing all the important libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d98ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e17f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dad4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing files from the google drive\n",
    "\n",
    "%%shell\n",
    "\n",
    "if [ ! -f CNN_assignment.zip ]; then\n",
    "    wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1xLfSQUGDl8ezNNbUkpuHOYvSpTyxVhCs&confirm=t' -O CNN_assignment.zip\n",
    "fi\n",
    "\n",
    "if [ ! -d 'Skin cancer ISIC The International Skin Imaging Collaboration' ]; then\n",
    "    unzip -q CNN_assignment.zip\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2ea69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f1eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "## Todo: Update the paths of the train and test dataset\n",
    "data_dir_train = pathlib.Path(\"Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
    "data_dir_test = pathlib.Path('Skin cancer ISIC The International Skin Imaging Collaboration/Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d13389",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a179d",
   "metadata": {},
   "source": [
    "# Load using keras.preprocessing\n",
    "Let's load these images off disk using the helpful image_dataset_from_directory utility.\n",
    "\n",
    "Create a dataset\n",
    "Define some parameters for the loader:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00d2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6e7b1",
   "metadata": {},
   "source": [
    "# Use 80% of the images for training, and 20% for validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810247ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your train dataset here\n",
    "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,image_size=(img_width,img_height),\n",
    "                                                               batch_size=batch_size,validation_split=0.2,\n",
    "                                                               subset='training',seed=123)##todo\n",
    "train_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your validation dataset here\n",
    "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
    "s.preprocessing.image_dataset_from_directory(data_dir_train,image_size=(img_width,img_height),\n",
    "                                                             batch_size=batch_size,validation_split=0.2,\n",
    "                                                             subset='validation',seed=123)##todo\n",
    "val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the classes of skin cancer and store them in a list. \n",
    "# You can find the class names in the class_names attribute on these datasets. \n",
    "# These correspond to the directory names in alphabetical order.\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize the data\n",
    "Todo, create a code to visualize one instance of all the nine classes present in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### your code goes here, you can use training or validation data to visualize\n",
    "\n",
    "from PIL import Image\n",
    "fig=plt.figure(figsize=(10,8))\n",
    "counter=1\n",
    "for f in data_dir_train.iterdir():\n",
    "  im=Image.open(f.iterdir().__next__())\n",
    "  plt.subplot(3,3,counter)\n",
    "  plt.imshow(im)\n",
    "  plt.title(str(f).split('/')[-1])\n",
    "  counter+=1\n",
    "  plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad897f21",
   "metadata": {},
   "source": [
    "The image_batch is a tensor of the shape (32, 180, 180, 3). This is a batch of 32 images of shape 180x180x3 (the last dimension refers to color channels RGB). The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.\n",
    "\n",
    "Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch.\n",
    "\n",
    "Dataset.prefetch() overlaps data preprocessing and model execution while training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8be845",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83b629",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use layers.experimental.preprocessing.Rescaling to normalize pixel values between (0,1). The RGB channel values are in the [0, 255] range. This is not ideal for a neural network. Here, it is good to standardize values to be in the [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f86dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here\n",
    "\n",
    "num_classes = 9\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255,input_shape=(180,180,3)),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1100cb",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "Choose an appropirate optimiser and loss function for model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Todo, choose an appropirate optimiser and loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183f66e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27772/74098765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# View the summary of all layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# View the summary of all layers\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3800ced",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857dd60",
   "metadata": {},
   "source": [
    "# Visualizing training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2efdb",
   "metadata": {},
   "source": [
    "Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit\n",
    "Write your findings here\n",
    "->There is clear evidence of model overfitting-\n",
    "\n",
    "Training accuracy is 0.84 after 20 epochs but validation accuracy is 0.52 (difference of 0.32)\n",
    "Training loss is going down after every epoch but validation loss is parabolic. In fact validation loss is going up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo, after you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n",
    "# Your code goes here\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04115c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo, visualize how your augmentation strategy works for one instance of training image.\n",
    "# Your code goes here\n",
    "for batch,labels in train_ds.take(1):\n",
    "  im=batch[0]\n",
    "  im=tf.reshape(im,(1,img_width,img_height,3))\n",
    "  \n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  augmented_image = data_augmentation(im)[0]\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(augmented_image.numpy().astype(\"uint8\"))\n",
    "  plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc61be7",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "Create the model, compile and train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can use Dropout layer if there is an evidence of overfitting in your findings\n",
    "\n",
    "## Your code goes here\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a709d5",
   "metadata": {},
   "source": [
    "# Compiling the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a42524",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa5d67",
   "metadata": {},
   "source": [
    "# Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be44a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here, note: train your model for 20 epochs\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")## your training code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ed8d0",
   "metadata": {},
   "source": [
    "# Visualizing the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b7194",
   "metadata": {},
   "source": [
    "Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?\n",
    "There is no evidence of overfitting. Training and validation accuraies are quite close (0.61, 0.54)\n",
    "\n",
    "There is evidence of underfitting because training and validation accuracies are quite low (<0.7)\n",
    "\n",
    "It looks like image augmentation got rid of overfitting\n",
    "\n",
    "Todo: Find the distribution of classes in the training dataset.\n",
    "Context: Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here.\n",
    "from glob import glob\n",
    "path_list = [x for x in glob(os.path.join(data_dir_train, '*', '*.jpg'))]\n",
    "lesion_list = [os.path.basename(os.path.dirname(y)) for y in glob(os.path.join(data_dir_train, '*', '*.jpg'))]\n",
    "dataframe_dict = dict(zip(path_list, lesion_list))\n",
    "original_df = pd.DataFrame(list(dataframe_dict.items()),columns = ['Path','Label'])\n",
    "original_df['Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc240f",
   "metadata": {},
   "source": [
    "# Todo: Write your findings here:\n",
    "- Which class has the least number of samples?\n",
    "->seborrheic keratosis\n",
    "\n",
    "- Which classes dominate the data in terms proportionate number of samples?\n",
    "->pigmented benign keratosis\n",
    "\n",
    "Todo: Rectify the class imbalance\n",
    "Context: You can use a python package known as Augmentor (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67db61ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Augmentor\n",
      "  Downloading Augmentor-0.2.10-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm>=4.9.0 in c:\\users\\inascha7\\anaconda3\\lib\\site-packages (from Augmentor) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\inascha7\\anaconda3\\lib\\site-packages (from Augmentor) (1.20.3)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\inascha7\\anaconda3\\lib\\site-packages (from Augmentor) (8.4.0)\n",
      "Requirement already satisfied: future>=0.16.0 in c:\\users\\inascha7\\anaconda3\\lib\\site-packages (from Augmentor) (0.18.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\inascha7\\anaconda3\\lib\\site-packages (from tqdm>=4.9.0->Augmentor) (0.4.4)\n",
      "Installing collected packages: Augmentor\n",
      "Successfully installed Augmentor-0.2.10\n"
     ]
    }
   ],
   "source": [
    "!pip install Augmentor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_dataset=str(data_dir_train)+'/'#'./Skin cancer ISIC The International Skin Imaging Collaboration/Train/'#\"To do\"\n",
    "import Augmentor\n",
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406eeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b972d",
   "metadata": {},
   "source": [
    "Lets see the distribution of augmented data after adding new images to the original training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "path_list_new = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "path_list_new[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "lesion_list_new[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a706d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
    "new_df = original_df.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f03691",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b78c41",
   "metadata": {},
   "source": [
    "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process.\n",
    "\n",
    "Todo: Train the model on the data created using Augmentor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a488cd",
   "metadata": {},
   "source": [
    "Todo: Create a training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_train=data_dir_train#\"Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'training',## Todo choose the correct parameter value, so that only training data is refered to,,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448baaca",
   "metadata": {},
   "source": [
    "Todo: Create a validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'validation',## Todo choose the correct parameter value, so that only validation data is refered to,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2df873",
   "metadata": {},
   "source": [
    "Todo: Create your model (make sure to include normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "\n",
    "num_classes = 9\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a91a1",
   "metadata": {},
   "source": [
    "Todo: Compile your model (Choose optimizer and loss function appropriately)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccb01d",
   "metadata": {},
   "source": [
    "Todo: Train your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here, use 50 epochs.\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")# your model fit code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3c7b8",
   "metadata": {},
   "source": [
    "Todo: Visualize the model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aaffe9",
   "metadata": {},
   "source": [
    "Todo: Analyze your results here. Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
    "I got rid of underfitting. Now training and validation accuracies are higher than previous model (0.82, 0.79)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eff612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on Test data is not upto the mark\n",
    "\n",
    "test_ds=tf.keras.preprocessing.image_dataset_from_directory(data_dir_test,image_size=(img_width,img_height),\n",
    "                                                            shuffle=False,batch_size=120)\n",
    "predictions=model.predict(test_ds)\n",
    "score = tf.nn.softmax(predictions)\n",
    "_, labels = tuple(zip(*test_ds))\n",
    "print(labels)\n",
    "print()\n",
    "print(np.argmax(score,axis=-1))\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Test Accuracy')\n",
    "accuracy_score(labels[0].numpy(),np.argmax(score,axis=-1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
